{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgKtTVe4ooDl"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score, confusion_matrix, precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D, Activation, BatchNormalization\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7an5ZxOgY8wM"
   },
   "outputs": [],
   "source": [
    "GLOBAL_SEED = 744\n",
    "os.environ['PYTHONHASHSEED'] = str(GLOBAL_SEED)\n",
    "random.seed(GLOBAL_SEED)\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "tf.random.set_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnJCDGu4o5r-"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 220, 360\n",
    "\n",
    "src_dir = '<path_to_your_dataset>'\n",
    "train_path = './train/'\n",
    "validation_path = './validation/'\n",
    "\n",
    "class_double_print = 'double'\n",
    "class_good = 'good'\n",
    "class_interrupted = 'interrupted'\n",
    "all_classes = [class_double_print, class_good, class_interrupted]\n",
    "\n",
    "model_file_name = 'shaver_shell_simple_conv_v2.h5'\n",
    "model_path = os.path.join('./models', model_file_name)\n",
    "\n",
    "X=[]\n",
    "Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_6tNUr8pw1b"
   },
   "outputs": [],
   "source": [
    "for i in range(len(all_classes)):\n",
    "    source_files=os.listdir(os.path.join(src_dir, all_classes[i]))\n",
    "    for f in source_files:\n",
    "        X.append(f)\n",
    "        Y.append(i)\n",
    "\n",
    "X=np.asarray(X)\n",
    "Y=np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrlZd93LqAOj"
   },
   "outputs": [],
   "source": [
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "def conv_net(conv_blocks = 1, filter_size = (3,3), no_filters = 16, is_init = True, is_last = True):\n",
    "  convnet = Sequential()\n",
    "  if is_init:\n",
    "      convnet.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=input_shape))\n",
    "      convnet.add(tf.keras.layers.experimental.preprocessing.Normalization())\n",
    "  for i in range(conv_blocks):\n",
    "      convnet.add(Conv2D(no_filters,filter_size,padding='same'))\n",
    "      convnet.add(BatchNormalization())\n",
    "      convnet.add(Activation('relu'))\n",
    "      convnet.add(tf.keras.layers.Dropout(0.4))\n",
    "      convnet.add(MaxPooling2D())\n",
    "  if is_last:\n",
    "      convnet.add(Flatten())\n",
    "  return convnet\n",
    "\n",
    "def create_model():  \n",
    "  inp = Input(input_shape)\n",
    "\n",
    "  base = conv_net()(inp)\n",
    "  detailed = conv_net(conv_blocks = 1, filter_size = (1,1), is_last = True)(inp)\n",
    "\n",
    "  concat_layer = tf.concat([base, detailed], axis = 1)\n",
    "  out = keras.layers.Dense(len(all_classes), activation=\"softmax\", \n",
    "                         kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.0001, l2=0.0001))(concat_layer)\n",
    "\n",
    "  model = Model([inp], out)\n",
    "  optimizer = Adam(0.00001)\n",
    "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqRm4IOGWbfY"
   },
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred, y_proba):\n",
    "    y_good = (y_true == all_classes.index('19-01 goed')).astype(int)\n",
    "    y_double_print = (y_true == all_classes.index('19-01 dubbeldruk')).astype(int)\n",
    "    y_interrupted = (y_true == all_classes.index('19-01 onderbroken')).astype(int)\n",
    "    res = {'binary_roc_auc': roc_auc_score(y_good, y_proba[:, all_classes.index('19-01 goed')]),\n",
    "            'binary_recall': recall_score(y_good, (y_pred == all_classes.index('19-01 goed')).astype(int), pos_label=0),\n",
    "            'multiclass_roc_auc': roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted'),\n",
    "            'binary_acc': accuracy_score(y_good, (y_pred == all_classes.index('19-01 goed')).astype(int)),\n",
    "            'multiclass_acc': accuracy_score(y_true, y_pred),\n",
    "            'recall_double_print': recall_score(y_double_print, (y_pred == all_classes.index('19-01 dubbeldruk')).astype(int), pos_label=1),\n",
    "            'recall_interrupted': recall_score(y_interrupted, (y_pred == all_classes.index('19-01 onderbroken')).astype(int), pos_label=1),\n",
    "            'prec_good': precision_score(y_good, (y_pred == all_classes.index('19-01 goed')).astype(int), pos_label=1),\n",
    "           }\n",
    "    print('Result: ' ,res)\n",
    "    return res\n",
    "\n",
    "class ReductionStratifiedKFold:\n",
    "    def __init__(self, n_splits=3, keep=1.0, good_class=1, shuffle=True, random_state=0):\n",
    "        self.n_splits = n_splits\n",
    "        self.random_state = random_state\n",
    "        self.good_class = good_class\n",
    "        self.keep = keep\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        for train, test in skf.split(X, y):\n",
    "            train_y = y[train]\n",
    "            train_new = [train[train_y == self.good_class]]\n",
    "            \n",
    "            for c in np.unique(y):\n",
    "                if c != self.good_class:\n",
    "                    c_inds = train[train_y == c]\n",
    "                    train_new.append(\n",
    "                        rng.choice(c_inds, round(len(c_inds) * self.keep), replace=False))\n",
    "            yield np.sort(np.concatenate(train_new)), test\n",
    "        \n",
    "    def get_n_splits(self, X, y, groups=None):\n",
    "        return self.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_number(class_label):\n",
    "    root_dir = '../input/shaver-shell-full-all-classes-v2/shaver-shell-full'\n",
    "    def aux():\n",
    "        path = os.path.join(root_dir, class_label)\n",
    "        return len(os.listdir(path))\n",
    "    return aux()\n",
    "\n",
    "def determine_class_weights():\n",
    "    weights = {}\n",
    "\n",
    "    target_number = get_instance_number('19-01 goed')\n",
    "\n",
    "    for cls_no, label in enumerate(all_classes):\n",
    "        actual_number = get_instance_number(label)\n",
    "        if actual_number < target_number:\n",
    "            weights[cls_no] = int(round((target_number - actual_number) / actual_number))\n",
    "        else:\n",
    "            weights[cls_no] = 1\n",
    "    \n",
    "    return weights\n",
    "\n",
    "cls_weights = determine_class_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_split_images(X, Y, dest):\n",
    "    for eachIndex in range(len(X)):\n",
    "        label=''\n",
    "        for i in range(len(all_classes)):\n",
    "            if(Y[eachIndex]==i):\n",
    "                label=all_classes[i]\n",
    "        shutil.copy(os.path.join(src_dir, label, X[eachIndex]), \n",
    "                    os.path.join(dest, label, X[eachIndex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Eey7KqgqUez",
    "outputId": "9018fc9d-5676-4d8c-a2df-97091a88d042"
   },
   "outputs": [],
   "source": [
    "# ===============Stratified K-Fold======================\n",
    "\n",
    "batch_size = 4\n",
    "val_split = 0.2\n",
    "\n",
    "all_results = []\n",
    "for keep in [1.0]: #1.00, 0.75, 0.5, 0.25]:\n",
    "  print(\"Results for keep: \",keep)\n",
    "  skf = ReductionStratifiedKFold(n_splits=10, keep=keep, # n_splits=10\n",
    "                                 good_class=all_classes.index('19-01 goed'),\n",
    "                                 random_state=GLOBAL_SEED)\n",
    "  foldNum=0\n",
    "\n",
    "  for train_index, val_index in skf.split(X, Y):\n",
    "    model=create_model()\n",
    "    \n",
    "    #Remove old split\n",
    "    if os.path.exists(validation_path):\n",
    "        shutil.rmtree(validation_path)\n",
    "    if os.path.exists(train_path):\n",
    "        shutil.rmtree(train_path)\n",
    "    \n",
    "    #Recreate paths\n",
    "    for label in all_classes:\n",
    "        os.makedirs( train_path+label, exist_ok = True)\n",
    "        os.makedirs( validation_path+label, exist_ok = True)\n",
    "\n",
    "    foldNum+=1\n",
    "    print(\"Results for fold: \", foldNum)\n",
    "    \n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "    \n",
    "    # Copy train images of this keep and fold from full_data to the train folder\n",
    "    copy_split_images(X_train, Y_train, train_path)\n",
    "    \n",
    "    # Copy validation images of this fold from full_data folder to the validation folder\n",
    "    copy_split_images(X_val, Y_val, validation_path)\n",
    "        \n",
    "    # Create data loaders\n",
    "    train_datagen = ImageDataGenerator(validation_split=val_split)\n",
    "    train_val_datagen = ImageDataGenerator(validation_split=val_split)\n",
    "    validation_datagen = ImageDataGenerator()\n",
    "        \n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode = \"grayscale\",\n",
    "        seed=GLOBAL_SEED,\n",
    "        subset='training')\n",
    "    \n",
    "    train_val_generator = train_val_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode = \"grayscale\",\n",
    "        seed=GLOBAL_SEED,\n",
    "        subset='validation')\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_path,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        color_mode = \"grayscale\",\n",
    "        seed=GLOBAL_SEED,\n",
    "        shuffle=False)   \n",
    "    \n",
    "    # fit model\n",
    "    mc = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, verbose = 1)\n",
    "    \n",
    "    # class_weight is for loss weighting, comment in or out accordingly\n",
    "    model.fit(train_generator, epochs=50, validation_data=train_val_generator, \n",
    "              shuffle=True, callbacks=[mc], verbose = 0) #, class_weight = cls_weights)  #epochs=200\n",
    "    \n",
    "    # Calculate results for current keep and split\n",
    "    model = tf.keras.models.load_model(model_path)  # load the best checkpointed model\n",
    "    predictions = model.predict_generator(validation_generator, verbose=1)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    true_classes = validation_generator.classes\n",
    "\n",
    "    r = calc_metrics(true_classes, y_pred, predictions)\n",
    "    r['model'] = 'custom_cnn'\n",
    "    r['keep'] = keep\n",
    "    r['fold'] = foldNum\n",
    "\n",
    "    all_results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = DataFrame.from_records(all_results)\n",
    "all_results.groupby(['model', 'keep']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9jtocbXpzSV"
   },
   "outputs": [],
   "source": [
    "all_results.to_csv('all_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
