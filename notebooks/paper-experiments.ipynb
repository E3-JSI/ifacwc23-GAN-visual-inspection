{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e4e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import utils\n",
    "from utils import evaluate_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ff093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler, ADASYN, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28417b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea850494",
   "metadata": {},
   "outputs": [],
   "source": [
    "shavers = utils.Shavers('<path_to_your_dataset>',\n",
    "                     normalize_transform=utils.normalize_resnet18)\n",
    "X = utils.get_resnet18_embeddings(shavers)\n",
    "\n",
    "y = np.array(shavers.targets)\n",
    "class_to_idx = shavers.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ea682",
   "metadata": {},
   "outputs": [],
   "source": [
    "val, cnt = np.unique(y, return_counts=True)\n",
    "i2c = {i:c for c, i in class_to_idx.items()}\n",
    "\n",
    "val = [i2c[x] for x in val]\n",
    "for v, c in zip(val, cnt):\n",
    "    print(v, \":\", c, round(c / len(y), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632ddbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.DataFrame()\n",
    "KEEP_RATIO = [1.0, 0.75, 0.5, 0.25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2637fd0d",
   "metadata": {},
   "source": [
    "### Include DRAEM anomaly maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ef9b6c",
   "metadata": {},
   "source": [
    "Generate anomaly maps for your dataset using **DRAEM-anomaly_maps.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b59c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "draem_heatmap = utils.Shavers('<path_to_anomaly_maps>',\n",
    "                     normalize_transform=utils.normalize_resnet18)\n",
    "X_heatmap = utils.get_resnet18_embeddings(draem_heatmap)\n",
    "y_heatmap = np.array(draem_heatmap.targets)\n",
    "assert all(y_heatmap == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34419d8",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcabce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comb = np.hstack([X, X_heatmap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline performance\n",
    "mlp = MLPClassifier(random_state=RANDOM_SEED, max_iter=10000)\n",
    "all_results = all_results.append(evaluate_keep(mlp, X, y, 'baseline'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd62a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline performance + DRAEM\n",
    "mlp = MLPClassifier(random_state=RANDOM_SEED, max_iter=10000)\n",
    "all_results = all_results.append(evaluate_keep(mlp, X_comb, y, 'baseline+draem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only DRAEM\n",
    "mlp = MLPClassifier(random_state=RANDOM_SEED, max_iter=10000)\n",
    "all_results = all_results.append(evaluate_keep(mlp, X_heatmap, y, 'baseline-onlydraem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install catboost\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "model = CatBoostClassifier(iterations=60, depth=10, loss_function='MultiClass')\n",
    "r = evaluate_keep(model, X, y, 'catboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c076c98d",
   "metadata": {},
   "source": [
    "### Over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72feecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random over-sampling\n",
    "mlp = MLPClassifier(random_state=RANDOM_SEED, max_iter=10000)\n",
    "sampler = RandomOverSampler(random_state=RANDOM_SEED)\n",
    "model = make_pipeline(sampler, mlp)\n",
    "all_results = all_results.append(evaluate_keep(model, X, y, 'random-oversample'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336205ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random over-sampling\n",
    "mlp = MLPClassifier(random_state=RANDOM_SEED, max_iter=10000)\n",
    "sampler = RandomOverSampler(random_state=RANDOM_SEED)\n",
    "model = make_pipeline(sampler, mlp)\n",
    "all_results = all_results.append(evaluate_keep(model, X_comb, y, 'random-oversample+draem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a46bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CatBoostClassifier(iterations=60, depth=10, loss_function='MultiClass')\n",
    "sampler = RandomOverSampler(random_state=RANDOM_SEED)\n",
    "model = make_pipeline(sampler, m)\n",
    "all_results = all_results.append(evaluate_keep(model, X, y, 'random-oversample-catboost'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random over-sampling\n",
    "mlp = MLPClassifier(random_state=RANDOM_SEED, max_iter=10000)\n",
    "sampler = ADASYN(random_state=RANDOM_SEED)\n",
    "model = make_pipeline(sampler, mlp)\n",
    "all_results = all_results.append(evaluate_keep(model, X, y, 'adasyn-oversample'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADASYN over-sampling => catboost\n",
    "m = CatBoostClassifier(iterations=60, depth=10, loss_function='MultiClass')\n",
    "sampler = ADASYN(random_state=RANDOM_SEED)\n",
    "model = make_pipeline(sampler, m)\n",
    "all_results = all_results.append(evaluate_keep(model, X, y, 'adasyn-oversample-catboost'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d6f9d",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbdba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "m = 20\n",
    "b_k = 2\n",
    "sampler = BorderlineSMOTE(random_state=RANDOM_SEED, k_neighbors=k, m_neighbors=m, kind=f'borderline-{b_k}')\n",
    "mlp = MLPClassifier(random_state=RANDOM_SEED, max_iter=10000)\n",
    "model = make_pipeline(sampler, mlp)\n",
    "all_results = all_results.append(evaluate_keep(model, X_comb, y, 'smote-oversample+draem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa88dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "m = 20\n",
    "b_k = 2\n",
    "sampler = BorderlineSMOTE(random_state=RANDOM_SEED, k_neighbors=k, m_neighbors=m, kind=f'borderline-{b_k}')\n",
    "m = CatBoostClassifier(iterations=60, depth=10, loss_function='MultiClass')\n",
    "model = make_pipeline(sampler, m)\n",
    "all_results = all_results.append(evaluate_keep(model, X, y, 'smote-oversample-catboost'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f2b3cd",
   "metadata": {},
   "source": [
    "### Augmentation with GAN images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2bd830",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = utils.Shavers('../lightweight-gan/generated/',\n",
    "                     normalize_transform=utils.normalize_resnet18)\n",
    "X_fake = utils.get_resnet18_embeddings(fake)\n",
    "y_fake = np.array(fake.targets)\n",
    "\n",
    "assert fake.class_to_idx == class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945ee7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = []\n",
    "for keep in tqdm(KEEP_RATIO):\n",
    "    cv = ReductionStratifiedKFold(n_splits=10, keep=keep, \n",
    "                                     good_class=class_to_idx['good'],\n",
    "                                     random_state=RANDOM_SEED)\n",
    "    scorer = make_custom_scorer(class_to_idx)\n",
    "    rng = np.random.RandomState(RANDOM_SEED)\n",
    "    \n",
    "    for fold, (train, test) in tqdm(enumerate(cv.split(X, y)), leave=False):\n",
    "        # Balance the classes with fake images\n",
    "        lbs, cnts = np.unique(y[train], return_counts=True)\n",
    "        inds = np.arange(len(y_fake))\n",
    "\n",
    "        fake_inds = []\n",
    "        for lb, cnt in zip(lbs, cnts):\n",
    "            fake_inds.append(\n",
    "                rng.choice(inds[y_fake == lb], cnts.max() - cnt))\n",
    "\n",
    "        fake_inds = np.concatenate(fake_inds)\n",
    "        xtr = np.vstack([X[train], X_fake[fake_inds]])\n",
    "        ytr = np.concatenate([y[train], y_fake[fake_inds]])\n",
    "      \n",
    "        mlp = MLPClassifier(random_state=RANDOM_SEED, max_iter=10000)\n",
    "        mlp.fit(xtr, ytr)\n",
    "        \n",
    "        d = scorer(mlp, X[test], y[test])\n",
    "        d.update({'model': 'gan', 'keep': keep, 'fold': fold})\n",
    "        rs.append(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfb5147",
   "metadata": {},
   "source": [
    "## Significance tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0290e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa74396",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'test_binary_recall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ee10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise comparison for all experiments\n",
    "pairs = []\n",
    "for m1, r1 in df.groupby('model'):\n",
    "    for m2, r2 in df.groupby('model'):\n",
    "        if m1 == m2: continue\n",
    "        pair = {'a': m1, 'b': m2}\n",
    "        \n",
    "        d = r1[column] - r2[column]\n",
    "        for alt in ['two-sided', 'greater', 'less']:\n",
    "            r = scipy.stats.wilcoxon(d, alternative=alt)\n",
    "            pair[alt + '_p'] = r.pvalue\n",
    "            pair[alt + '_s'] = r.statistic\n",
    "            \n",
    "        pairs.append(pair)\n",
    "pairs = pd.DataFrame(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203e6adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[['a', 'b', 'two-sided_p', 'greater_p', 'less_p']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
